{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spheronisation_Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZrDHbFUAoOec7RZa2iHtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slowbrain-jaym/Spheronisation-Inference/blob/main/Spheronisation_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLrSS7Q81Mrz"
      },
      "source": [
        "# Spheronisation Inference Workbook\n",
        "\n",
        "Workbook sets up a tensorflow object detection environment, loads a trained neural network and performs inference to locate and classify pellets within the spheroniser.\n",
        "\n",
        "How to use:\n",
        "1. Run the first 5 code cells up to the next text cell titled \"inference\". These code cells load the required libraries and files for inference.\n",
        "2. These cells will also create a folder labelled \"images\" that you can access in the folder explorer on the left hand side of the colab page. Upload images for inference into this folder.\n",
        "3. Run the inference cells below to create labelled versions of the images as well as a .csv file with all the detected pellets and their categories\n",
        "\n",
        "First we create a folder tree and download the trained model and tensorflow object detection libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l_ii1Xq1Jbw",
        "outputId": "bfa6c833-5237-4efe-8e33-19a996148b72"
      },
      "source": [
        "%mkdir workspace\n",
        "%cd /content/workspace\n",
        "%mkdir images results "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5GvX-x6drCq"
      },
      "source": [
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "!git clone --q https://github.com/slowbrain-jaym/SpheronisationCategorisation.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBqTzOcG2c3I"
      },
      "source": [
        "Next we install the tensorflow dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIT_6YLeBuoA"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIXfczILd0Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0786f06-d276-4c01-8223-3f6d03fc61b9"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib!pip install -qq pycocotools\n",
        "%cd models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[31mERROR: Invalid requirement: 'matplotlib!pip'\u001b[0m\n",
            "/content/workspace/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtG3Z9XG2iAJ"
      },
      "source": [
        "Installing tensorflow object detection and running the test function (this may take a couple of minutes to run)\n",
        "\n",
        "If the installation is successful a message similar to \"Ran 20 tests in 43.245s\" will be displayed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yl4sXbcd2TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf5cfb2-ae38-4976-809f-368a472e7eaf"
      },
      "source": [
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/workspace/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/5a/819537be46d65a01f8b8c6046ed05603fb9ef88c663b8cca840263788d58/avro-python3-1.10.0.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/3f/93816e989e8e59b337f22927778494a99b2a3e78a3b6a9e34d043c6fab4e/apache_beam-2.25.0-cp36-cp36m-manylinux2010_x86_64.whl (8.7MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.4)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/33/91e5e90e3e96292717245d3fe87eb3b35b07c8a2113f2da7f482040facdb/tf_models_official-2.3.0-py2.py3-none-any.whl (840kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 36.2MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.33.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/fc/f91eac5a39a65f75a7adb58eac7fa78871ea9872283fb9c44e6545998134/requests-2.25.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 44.4MB/s \n",
            "\u001b[?25hCollecting pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/3f/6cac1714fff444664603f92cb9fbe91c7ae25375880158b9e9691c4584c8/pyarrow-0.17.1-cp36-cp36m-manylinux2014_x86_64.whl (63.8MB)\n",
            "\u001b[K     |████████████████████████████████| 63.8MB 60kB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/a9/473ef678c8862d74c63e11d14afbdbeabe67f92fedd82405de5337d7e6de/fastavro-1.2.0-cp36-cp36m-manylinux2014_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (50.3.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.9)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.10.0)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)\n",
            "\u001b[K     |████████████████████████████████| 36.7MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Collecting pbr>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (0.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, future, hdfs, dill, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1598976 sha256=bafceca732bed5132ac4c9422e9b690faad671568638b97478644d56bc27e51a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5u499i5t/wheels/64/92/89/c06c83f17633e75a93a21c8dd8150e3e48346f4cf4c03f429b\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.0-cp36-none-any.whl size=43735 sha256=205fab8bc819e9ae82228f5b555dc24a3f5af8449d3def00c0009b0f34e9867a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/15/cd/fe4ec8b88c130393464703ee8111e2cddebdc40e1b59ea85e9\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=8981217dcba22a2cb1eddcb64a76132a73475cf5f358a6e782171c03e7359063\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=4bb0074ed9229bb408dbff1170ef760b934d141d7cb94eaaded72787d5d5353e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=2d51d9f1b25b8ff23a884d70ff4282aad9b3c4c175dd9b8f17520325041afeee\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20071 sha256=67f7777536ab78575d513917d2a173a66bd61b7eb57cc09dba18ffbd49d9ca52\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "Successfully built object-detection avro-python3 future hdfs dill py-cpuinfo\n",
            "\u001b[31mERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.25.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\", but you'll have avro-python3 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, future, pbr, mock, requests, hdfs, dill, pyarrow, fastavro, apache-beam, tf-slim, lvis, tensorflow-model-optimization, sentencepiece, opencv-python-headless, py-cpuinfo, tf-models-official, object-detection\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed apache-beam-2.25.0 avro-python3-1.10.0 dill-0.3.1.1 fastavro-1.2.0 future-0.18.2 hdfs-2.5.8 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.4.0.46 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-0.17.1 requests-2.25.0 sentencepiece-0.1.94 tensorflow-model-optimization-0.5.0 tf-models-official-2.3.0 tf-slim-1.1.0\n",
            "2020-11-19 19:43:32.767694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2020-11-19 19:43:37.088853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-19 19:43:37.225366: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-11-19 19:43:37.225437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0f8d277d77a3): /proc/driver/nvidia/version does not exist\n",
            "2020-11-19 19:43:37.278160: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-11-19 19:43:37.278505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x31152c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-19 19:43:37.278548: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 6.92s\n",
            "I1119 19:43:43.601948 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 6.92s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1119 19:43:43.603637 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I1119 19:43:43.647784 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I1119 19:43:43.674174 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I1119 19:43:43.702019 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n",
            "I1119 19:43:43.890963 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "I1119 19:43:44.063839 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n",
            "I1119 19:43:44.240654 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n",
            "I1119 19:43:44.415677 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "I1119 19:43:44.594522 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I1119 19:43:44.645710 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1119 19:43:45.016148 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1119 19:43:45.016520 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n",
            "I1119 19:43:45.016690 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n",
            "I1119 19:43:45.026389 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:45.055380 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:45.055601 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:45.140010 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:45.140220 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:45.369498 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:45.369701 140155899479936 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1119 19:43:45.603384 140155899479936 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1119 19:43:45.603616 140155899479936 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1119 19:43:45.997009 140155899479936 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1119 19:43:45.997225 140155899479936 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1119 19:43:46.382699 140155899479936 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1119 19:43:46.382957 140155899479936 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1119 19:43:47.137116 140155899479936 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1119 19:43:47.137333 140155899479936 efficientnet_model.py:148] round_filter input=320 output=320\n",
            "I1119 19:43:47.264707 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=1280\n",
            "I1119 19:43:47.336961 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:43:47.437197 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1119 19:43:47.437419 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n",
            "I1119 19:43:47.437512 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n",
            "I1119 19:43:47.444251 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:47.471623 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:47.471854 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:47.651947 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:47.652152 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:48.023168 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:48.023381 140155899479936 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1119 19:43:48.381785 140155899479936 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1119 19:43:48.382005 140155899479936 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1119 19:43:48.901933 140155899479936 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1119 19:43:48.902151 140155899479936 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1119 19:43:49.415578 140155899479936 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1119 19:43:49.415814 140155899479936 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1119 19:43:50.117610 140155899479936 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1119 19:43:50.117851 140155899479936 efficientnet_model.py:148] round_filter input=320 output=320\n",
            "I1119 19:43:50.410620 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=1280\n",
            "I1119 19:43:50.478852 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:43:50.593483 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1119 19:43:50.593716 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n",
            "I1119 19:43:50.593823 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n",
            "I1119 19:43:50.600607 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:50.626907 140155899479936 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1119 19:43:50.627122 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:51.058804 140155899479936 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1119 19:43:51.059072 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:51.427701 140155899479936 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1119 19:43:51.427944 140155899479936 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1119 19:43:51.794574 140155899479936 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1119 19:43:51.794811 140155899479936 efficientnet_model.py:148] round_filter input=80 output=88\n",
            "I1119 19:43:52.314570 140155899479936 efficientnet_model.py:148] round_filter input=80 output=88\n",
            "I1119 19:43:52.314812 140155899479936 efficientnet_model.py:148] round_filter input=112 output=120\n",
            "I1119 19:43:52.828121 140155899479936 efficientnet_model.py:148] round_filter input=112 output=120\n",
            "I1119 19:43:52.828338 140155899479936 efficientnet_model.py:148] round_filter input=192 output=208\n",
            "I1119 19:43:53.543371 140155899479936 efficientnet_model.py:148] round_filter input=192 output=208\n",
            "I1119 19:43:53.543618 140155899479936 efficientnet_model.py:148] round_filter input=320 output=352\n",
            "I1119 19:43:53.854222 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=1408\n",
            "I1119 19:43:53.939535 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:43:54.056614 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1119 19:43:54.056846 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n",
            "I1119 19:43:54.056941 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n",
            "I1119 19:43:54.063694 140155899479936 efficientnet_model.py:148] round_filter input=32 output=40\n",
            "I1119 19:43:54.094159 140155899479936 efficientnet_model.py:148] round_filter input=32 output=40\n",
            "I1119 19:43:54.094364 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:43:54.266496 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:43:54.266709 140155899479936 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1119 19:43:54.638831 140155899479936 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1119 19:43:54.639065 140155899479936 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1119 19:43:55.023715 140155899479936 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1119 19:43:55.023948 140155899479936 efficientnet_model.py:148] round_filter input=80 output=96\n",
            "I1119 19:43:55.647256 140155899479936 efficientnet_model.py:148] round_filter input=80 output=96\n",
            "I1119 19:43:55.647476 140155899479936 efficientnet_model.py:148] round_filter input=112 output=136\n",
            "I1119 19:43:56.584115 140155899479936 efficientnet_model.py:148] round_filter input=112 output=136\n",
            "I1119 19:43:56.584352 140155899479936 efficientnet_model.py:148] round_filter input=192 output=232\n",
            "I1119 19:43:57.487900 140155899479936 efficientnet_model.py:148] round_filter input=192 output=232\n",
            "I1119 19:43:57.488170 140155899479936 efficientnet_model.py:148] round_filter input=320 output=384\n",
            "I1119 19:43:57.831206 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=1536\n",
            "I1119 19:43:57.923211 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:43:58.070009 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1119 19:43:58.070230 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n",
            "I1119 19:43:58.070322 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I1119 19:43:58.077008 140155899479936 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1119 19:43:58.107915 140155899479936 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1119 19:43:58.108166 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:43:58.293420 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:43:58.293706 140155899479936 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1119 19:43:58.776177 140155899479936 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1119 19:43:58.776396 140155899479936 efficientnet_model.py:148] round_filter input=40 output=56\n",
            "I1119 19:43:59.281404 140155899479936 efficientnet_model.py:148] round_filter input=40 output=56\n",
            "I1119 19:43:59.281617 140155899479936 efficientnet_model.py:148] round_filter input=80 output=112\n",
            "I1119 19:44:00.060901 140155899479936 efficientnet_model.py:148] round_filter input=80 output=112\n",
            "I1119 19:44:00.061172 140155899479936 efficientnet_model.py:148] round_filter input=112 output=160\n",
            "I1119 19:44:00.877915 140155899479936 efficientnet_model.py:148] round_filter input=112 output=160\n",
            "I1119 19:44:00.878128 140155899479936 efficientnet_model.py:148] round_filter input=192 output=272\n",
            "I1119 19:44:02.170508 140155899479936 efficientnet_model.py:148] round_filter input=192 output=272\n",
            "I1119 19:44:02.170764 140155899479936 efficientnet_model.py:148] round_filter input=320 output=448\n",
            "I1119 19:44:02.535366 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=1792\n",
            "I1119 19:44:02.631477 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:44:02.777659 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1119 19:44:02.777894 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n",
            "I1119 19:44:02.777988 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I1119 19:44:02.784961 140155899479936 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1119 19:44:02.812334 140155899479936 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1119 19:44:02.812564 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:44:03.401862 140155899479936 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1119 19:44:03.402086 140155899479936 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1119 19:44:04.004528 140155899479936 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1119 19:44:04.004792 140155899479936 efficientnet_model.py:148] round_filter input=40 output=64\n",
            "I1119 19:44:04.627598 140155899479936 efficientnet_model.py:148] round_filter input=40 output=64\n",
            "I1119 19:44:04.627856 140155899479936 efficientnet_model.py:148] round_filter input=80 output=128\n",
            "I1119 19:44:05.522647 140155899479936 efficientnet_model.py:148] round_filter input=80 output=128\n",
            "I1119 19:44:05.522896 140155899479936 efficientnet_model.py:148] round_filter input=112 output=176\n",
            "I1119 19:44:06.528322 140155899479936 efficientnet_model.py:148] round_filter input=112 output=176\n",
            "I1119 19:44:06.528541 140155899479936 efficientnet_model.py:148] round_filter input=192 output=304\n",
            "I1119 19:44:08.004183 140155899479936 efficientnet_model.py:148] round_filter input=192 output=304\n",
            "I1119 19:44:08.004410 140155899479936 efficientnet_model.py:148] round_filter input=320 output=512\n",
            "I1119 19:44:08.621793 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=2048\n",
            "I1119 19:44:08.728976 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:44:08.885300 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1119 19:44:08.885643 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I1119 19:44:08.885798 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I1119 19:44:08.896720 140155899479936 efficientnet_model.py:148] round_filter input=32 output=56\n",
            "I1119 19:44:08.924598 140155899479936 efficientnet_model.py:148] round_filter input=32 output=56\n",
            "I1119 19:44:08.924827 140155899479936 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1119 19:44:09.206491 140155899479936 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1119 19:44:09.206713 140155899479936 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1119 19:44:09.949873 140155899479936 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1119 19:44:09.950098 140155899479936 efficientnet_model.py:148] round_filter input=40 output=72\n",
            "I1119 19:44:10.709987 140155899479936 efficientnet_model.py:148] round_filter input=40 output=72\n",
            "I1119 19:44:10.710194 140155899479936 efficientnet_model.py:148] round_filter input=80 output=144\n",
            "I1119 19:44:12.153230 140155899479936 efficientnet_model.py:148] round_filter input=80 output=144\n",
            "I1119 19:44:12.153481 140155899479936 efficientnet_model.py:148] round_filter input=112 output=200\n",
            "I1119 19:44:13.297662 140155899479936 efficientnet_model.py:148] round_filter input=112 output=200\n",
            "I1119 19:44:13.297898 140155899479936 efficientnet_model.py:148] round_filter input=192 output=344\n",
            "I1119 19:44:15.159971 140155899479936 efficientnet_model.py:148] round_filter input=192 output=344\n",
            "I1119 19:44:15.160191 140155899479936 efficientnet_model.py:148] round_filter input=320 output=576\n",
            "I1119 19:44:15.858590 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=2304\n",
            "I1119 19:44:15.972095 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1119 19:44:16.155326 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1119 19:44:16.155538 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I1119 19:44:16.155630 140155899479936 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I1119 19:44:16.162319 140155899479936 efficientnet_model.py:148] round_filter input=32 output=64\n",
            "I1119 19:44:16.188293 140155899479936 efficientnet_model.py:148] round_filter input=32 output=64\n",
            "I1119 19:44:16.188500 140155899479936 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1119 19:44:16.555125 140155899479936 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1119 19:44:16.555330 140155899479936 efficientnet_model.py:148] round_filter input=24 output=48\n",
            "I1119 19:44:17.459258 140155899479936 efficientnet_model.py:148] round_filter input=24 output=48\n",
            "I1119 19:44:17.459473 140155899479936 efficientnet_model.py:148] round_filter input=40 output=80\n",
            "I1119 19:44:18.329430 140155899479936 efficientnet_model.py:148] round_filter input=40 output=80\n",
            "I1119 19:44:18.329640 140155899479936 efficientnet_model.py:148] round_filter input=80 output=160\n",
            "I1119 19:44:19.657777 140155899479936 efficientnet_model.py:148] round_filter input=80 output=160\n",
            "I1119 19:44:19.657991 140155899479936 efficientnet_model.py:148] round_filter input=112 output=224\n",
            "I1119 19:44:21.116180 140155899479936 efficientnet_model.py:148] round_filter input=112 output=224\n",
            "I1119 19:44:21.116399 140155899479936 efficientnet_model.py:148] round_filter input=192 output=384\n",
            "I1119 19:44:23.927110 140155899479936 efficientnet_model.py:148] round_filter input=192 output=384\n",
            "I1119 19:44:23.927321 140155899479936 efficientnet_model.py:148] round_filter input=320 output=640\n",
            "I1119 19:44:24.977301 140155899479936 efficientnet_model.py:148] round_filter input=1280 output=2560\n",
            "I1119 19:44:25.109216 140155899479936 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.67s\n",
            "I1119 19:44:25.315047 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1119 19:44:25.324850 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1119 19:44:25.327588 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1119 19:44:25.328843 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1119 19:44:25.331020 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1119 19:44:25.333204 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1119 19:44:25.333961 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1119 19:44:25.335280 140155899479936 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 48.658s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0EF1630N24",
        "outputId": "9efc0a78-7be4-4626-9d75-0a3abbd7cb0d"
      },
      "source": [
        "%cd /content/workspace"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcDR8cM1wXj"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Environment is now setup, we can perform inference.\n",
        "\n",
        "Upload the images that inference is to be performed on to the \"workspace/images\" directory. Make sure that there are no non image files in this directory and there are no other directories within it.\n",
        "\n",
        "# Outputs\n",
        "Two files are output to the workspace/results folder:\n",
        "* labelled_images.png - all the images for which inference has been performed with label boxes drawn on them, useful for visually inspecting how accurate the inference has been\n",
        "* detections.csv - a list of all the objects detected with classification, certainty, coordinates and image name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZJ8MNxQxpBN",
        "outputId": "cb15d5d4-53d4-46b7-9a02-cf53be041957"
      },
      "source": [
        "# importing the required libraries\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/window_detection/models/:/content/window_detection/models/research/:/content/window_detection/models/research/slim/'\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = \"/content/workspace/SpheronisationCategorisation/mobilenet640x640/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL) # loading the trained model\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...Done! Took 11.665812015533447 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW6HL-LDyLtU"
      },
      "source": [
        "# loading the tensorflow label map file\n",
        "PATH_TO_LABELS = '/content/workspace/SpheronisationCategorisation/mobilenet640x640/label_map.pbtxt'\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsUA31OFyRgr"
      },
      "source": [
        "image_path = \"/content/workspace/images\"\n",
        "IMAGE_PATHS = [f for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))] \n",
        "        # getting the file names for all the images in the image folder"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVxHyfSPzcEj",
        "outputId": "3c362c62-2095-4c62-f319-6646315ec9d2"
      },
      "source": [
        "# Perform inference on all the images in the images folder\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "allresults = []\n",
        "labelled_images = {}\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for image_name in IMAGE_PATHS:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_name), end='')\n",
        "\n",
        "    image_path = \"/content/workspace/images/\" + image_name\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "    \n",
        "    img_results = {}\n",
        "    img_results[\"category\"] = [category_index[id]['name'] for id in detections['detection_classes']]\n",
        "    img_results[\"x1\"] = [coord[0] for coord in detections['detection_boxes']]\n",
        "    img_results[\"y1\"] = [coord[1] for coord in detections['detection_boxes']]\n",
        "    img_results[\"x2\"] = [coord[2] for coord in detections['detection_boxes']]\n",
        "    img_results[\"y2\"] = [coord[3] for coord in detections['detection_boxes']]\n",
        "    img_results[\"certainty\"] = detections['detection_scores']\n",
        "    img_results = pd.DataFrame(img_results)\n",
        "    img_results[\"image\"] = image_name\n",
        "\n",
        "    allresults.append(img_results)\n",
        "\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    plt.savefig(\"results/labelled_\"+image_name, dpi=2000)\n",
        "    print('Done')\n",
        "#plt.show()\n",
        "\n",
        "allresults = pd.concat(allresults)\n",
        "allresults.to_csv(\"results/detections.csv\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running inference for b (65).jpg... Done\n",
            "Running inference for b (45).jpg... Done\n",
            "Running inference for b (23).jpg... Done\n",
            "Running inference for b (78).jpg... Done\n",
            "Running inference for b (38).jpg... Done\n",
            "Running inference for b (32).jpg... Done\n",
            "Running inference for b (55).jpg... Done\n",
            "Running inference for b (2).jpg... Done\n",
            "Running inference for b (76).jpg... Done\n",
            "Running inference for b (125).jpg... Done\n",
            "Running inference for b (77).jpg... Done\n",
            "Running inference for b (56).jpg... Done\n",
            "Running inference for b.jpg... Done\n",
            "Running inference for 5a 132dot8 crop.jpg... Done\n",
            "Running inference for b (72).jpg... Done\n",
            "Running inference for b (69).jpg... Done\n",
            "Running inference for b (88).jpg... Done\n",
            "Running inference for b (44).jpg... Done\n",
            "Running inference for b (75).jpg... Done\n",
            "Running inference for b (74).jpg... Done\n",
            "Running inference for b (37).jpg... Done\n",
            "Running inference for b (33).jpg... Done\n",
            "Running inference for b (108).jpg... Done\n",
            "Running inference for b (124).jpg... Done\n",
            "Running inference for b (136).jpg... Done\n",
            "Running inference for b (50).jpg... Done\n",
            "Running inference for b (85).jpg... Done\n",
            "Running inference for b (83).jpg... Done\n",
            "Running inference for b (42).jpg... Done\n",
            "Running inference for b (93).jpg... Done\n",
            "Running inference for b (139).jpg... Done\n",
            "Running inference for b (53).jpg... Done\n",
            "Running inference for b (2) - crop.jpg... Done\n",
            "Running inference for b (26).jpg... Done\n",
            "Running inference for b (134).jpg... Done\n",
            "Running inference for b (89).jpg... Done\n",
            "Running inference for b (40).jpg... Done\n",
            "Running inference for b (47).jpg... Done\n",
            "Running inference for b (87).jpg... Done\n",
            "Running inference for b (68).jpg... Done\n",
            "Running inference for b (35).jpg... Done\n",
            "Running inference for b (61).jpg... Done\n",
            "Running inference for b (91).jpg... Done\n",
            "Running inference for b (84).jpg... Done\n",
            "Running inference for b (70).jpg... Done\n",
            "Running inference for b (30).jpg... Done\n",
            "Running inference for b (46).jpg... Done\n",
            "Running inference for b (82).jpg... Done\n",
            "Running inference for b (22).jpg... Done\n",
            "Running inference for b (95).jpg... Done\n",
            "Running inference for b (39).jpg... Done\n",
            "Running inference for b (43).jpg... Done\n",
            "Running inference for b (96).jpg... Done\n",
            "Running inference for b (54).jpg... Done\n",
            "Running inference for b (60).jpg... Done\n",
            "Running inference for b (130).jpg... Done\n",
            "Running inference for b (138).jpg... Done\n",
            "Running inference for b (31).jpg... Done\n",
            "Running inference for b (1).jpg... Done\n",
            "Running inference for b (137).jpg... Done\n",
            "Running inference for b (90).jpg... Done\n",
            "Running inference for b (123).jpg... Done\n",
            "Running inference for b (62).jpg... Done\n",
            "Running inference for b (3).jpg... Done\n",
            "Running inference for b (127).jpg... Done\n",
            "Running inference for b (80).jpg... Done\n",
            "Running inference for b (25).jpg... Done\n",
            "Running inference for b (34).jpg... Done\n",
            "Running inference for b (41).jpg... Done\n",
            "Running inference for b (4).jpg... Done\n",
            "Running inference for b (29).jpg... Done\n",
            "Running inference for b (57).jpg... Done\n",
            "Running inference for b (94).jpg... Done\n",
            "Running inference for b (28).jpg... Done\n",
            "Running inference for b (48).jpg... Done\n",
            "Running inference for b (36).jpg... Done\n",
            "Running inference for b (86).jpg... Done\n",
            "Running inference for b (92).jpg... Done\n",
            "Running inference for b (131).jpg... Done\n",
            "Running inference for b (67).jpg... Done\n",
            "Running inference for b (71).jpg... Done\n",
            "Running inference for b (64).jpg... Done\n",
            "Running inference for b (49).jpg... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rm9A-QVpA0G"
      },
      "source": [
        "Now results are generated you can zip them and download them, this may take a while"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ezk6FwFAwQi",
        "outputId": "0ed7277b-5ce2-45a9-a2f8-b655580cb5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/workspace/results.zip /content/workspace/results\n",
        "files.download(\"/content/workspace/results.zip\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: content/workspace/results/ (stored 0%)\n",
            "updating: content/workspace/results/labelled_b (87).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (26).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (46).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (95).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (45).jpg (deflated 11%)\n",
            "updating: content/workspace/results/labelled_b (35).jpg (deflated 18%)\n",
            "updating: content/workspace/results/labelled_b (127).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (53).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (55).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (50).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (90).jpg (deflated 10%)\n",
            "updating: content/workspace/results/labelled_b (84).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (38).jpg (deflated 17%)\n",
            "updating: content/workspace/results/detections.csv (deflated 63%)\n",
            "updating: content/workspace/results/labelled_b (92).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (34).jpg (deflated 17%)\n",
            "updating: content/workspace/results/labelled_b (123).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (91).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (82).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (94).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (134).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (124).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (3).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (40).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (108).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (76).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (69).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (42).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (68).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (31).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (23).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (96).jpg (deflated 8%)\n",
            "updating: content/workspace/results/labelled_b (57).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (71).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (88).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (47).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (62).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (78).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (48).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (83).jpg (deflated 10%)\n",
            "updating: content/workspace/results/labelled_b (125).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (37).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (64).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (28).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (67).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (93).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (89).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (49).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (131).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (65).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (2) - crop.jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (74).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (138).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (2).jpg (deflated 8%)\n",
            "updating: content/workspace/results/labelled_b (72).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (32).jpg (deflated 16%)\n",
            "updating: content/workspace/results/labelled_b (56).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (86).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (54).jpg (deflated 11%)\n",
            "updating: content/workspace/results/labelled_b (43).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (33).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (75).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (25).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (80).jpg (deflated 11%)\n",
            "updating: content/workspace/results/labelled_b (137).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (22).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (77).jpg (deflated 12%)\n",
            "updating: content/workspace/results/labelled_b (41).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_5a 132dot8 crop.jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (136).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (30).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (44).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (36).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (1).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (85).jpg (deflated 9%)\n",
            "updating: content/workspace/results/labelled_b (130).jpg (deflated 17%)\n",
            "updating: content/workspace/results/labelled_b.jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (39).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (29).jpg (deflated 13%)\n",
            "updating: content/workspace/results/labelled_b (70).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (139).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (61).jpg (deflated 15%)\n",
            "updating: content/workspace/results/labelled_b (60).jpg (deflated 14%)\n",
            "updating: content/workspace/results/labelled_b (4).jpg (deflated 15%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_dcf37651-871e-41a8-844c-8412a6cefb4a\", \"results.zip\", 561959108)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-vxycYNpE__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}